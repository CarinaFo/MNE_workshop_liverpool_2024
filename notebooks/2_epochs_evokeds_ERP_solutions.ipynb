{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG analysis in MNE Python\n",
    "\n",
    "Aim: visualize epochs and evokeds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author: Carina Forster\n",
    "\n",
    "contact: forster@cbs.mpg.de\n",
    "\n",
    "last updated 27.06.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events and ERPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file C:\\Users\\Carina\\Desktop\\data_liverpool\\before_ica-raw.fif...\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n",
      "Opening raw data file C:\\Users\\Carina\\Desktop\\data_liverpool\\after_prepro_and_ica-raw.fif...\n",
      "    Range : 25800 ... 192599 =     42.956 ...   320.670 secs\n",
      "Ready.\n"
     ]
    }
   ],
   "source": [
    "# load the raw data before and after ica cleaning\n",
    "data_dir = Path(\"C:/\", \"Users\", \"Carina\", \"Desktop\", \"data_liverpool\")\n",
    "raw = mne.io.read_raw_fif(Path(data_dir, 'before_ica-raw.fif'))\n",
    "cleaned_raw = mne.io.read_raw_fif(Path(data_dir, 'after_prepro_and_ica-raw.fif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib as 2D backend.\n"
     ]
    }
   ],
   "source": [
    "# looks good? \n",
    "\n",
    "cleaned_raw.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<details open>\n",
       "    <summary><strong>General</strong></summary>\n",
       "    <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "        <tr>\n",
       "            <th>Measurement date</th>\n",
       "            \n",
       "            <td>December 03, 2002  19:01:10 GMT</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Experimenter</th>\n",
       "            \n",
       "            <td>MEG</td>\n",
       "            \n",
       "        </tr>\n",
       "        <tr>\n",
       "            <th>Participant</th>\n",
       "            \n",
       "            <td>Unknown</td>\n",
       "            \n",
       "        </tr>\n",
       "    </table>\n",
       "    </details>\n",
       "    <details open>\n",
       "        <summary><strong>Channels</strong></summary>\n",
       "        <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "            <tr>\n",
       "                <th>Digitized points</th>\n",
       "                \n",
       "                <td>146 points</td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Good channels</th>\n",
       "                <td>9 Stimulus, 59 EEG, 1 EOG</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>Bad channels</th>\n",
       "                <td>None</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>EOG channels</th>\n",
       "                <td>EOG 061</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <th>ECG channels</th>\n",
       "                <td>Not available</td>\n",
       "            </tr>\n",
       "        </table>\n",
       "        </details>\n",
       "        <details open>\n",
       "            <summary><strong>Data</strong></summary>\n",
       "            <table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "                \n",
       "                <tr>\n",
       "                    <th>Sampling frequency</th>\n",
       "                    <td>600.61 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Highpass</th>\n",
       "                    <td>0.10 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                <tr>\n",
       "                    <th>Lowpass</th>\n",
       "                    <td>30.00 Hz</td>\n",
       "                </tr>\n",
       "                \n",
       "                \n",
       "                \n",
       "                \n",
       "            </table>\n",
       "            </details>"
      ],
      "text/plain": [
       "<Info | 19 non-empty values\n",
       " acq_pars: ACQch001 110113 ACQch002 110112 ACQch003 110111 ACQch004 110122 ...\n",
       " bads: []\n",
       " ch_names: STI 001, STI 002, STI 003, STI 004, STI 005, STI 006, STI 014, ...\n",
       " chs: 9 Stimulus, 59 EEG, 1 EOG\n",
       " custom_ref_applied: False\n",
       " description: acquisition (megacq) VectorView system at NMR-MGH\n",
       " dev_head_t: MEG device -> head transform\n",
       " dig: 146 items (3 Cardinal, 4 HPI, 61 EEG, 78 Extra)\n",
       " events: 1 item (list)\n",
       " experimenter: MEG\n",
       " file_id: 4 items (dict)\n",
       " highpass: 0.1 Hz\n",
       " hpi_meas: 1 item (list)\n",
       " hpi_results: 1 item (list)\n",
       " lowpass: 30.0 Hz\n",
       " meas_date: 2002-12-03 19:01:10 UTC\n",
       " meas_id: 4 items (dict)\n",
       " nchan: 69\n",
       " proj_id: 1 item (ndarray)\n",
       " proj_name: test\n",
       " projs: []\n",
       " sfreq: 600.6 Hz\n",
       ">"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_raw.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Discussion:</b>\n",
    "\n",
    "How can we segment the data? \n",
    "\n",
    "Why do we segment the data?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['STI 001',\n",
       " 'STI 002',\n",
       " 'STI 003',\n",
       " 'STI 004',\n",
       " 'STI 005',\n",
       " 'STI 006',\n",
       " 'STI 014',\n",
       " 'STI 015',\n",
       " 'STI 016',\n",
       " 'EEG 001',\n",
       " 'EEG 002',\n",
       " 'EEG 003',\n",
       " 'EEG 004',\n",
       " 'EEG 005',\n",
       " 'EEG 006',\n",
       " 'EEG 007',\n",
       " 'EEG 008',\n",
       " 'EEG 009',\n",
       " 'EEG 010',\n",
       " 'EEG 011',\n",
       " 'EEG 012',\n",
       " 'EEG 013',\n",
       " 'EEG 014',\n",
       " 'EEG 015',\n",
       " 'EEG 016',\n",
       " 'EEG 017',\n",
       " 'EEG 018',\n",
       " 'EEG 019',\n",
       " 'EEG 020',\n",
       " 'EEG 021',\n",
       " 'EEG 022',\n",
       " 'EEG 023',\n",
       " 'EEG 024',\n",
       " 'EEG 025',\n",
       " 'EEG 026',\n",
       " 'EEG 027',\n",
       " 'EEG 028',\n",
       " 'EEG 029',\n",
       " 'EEG 030',\n",
       " 'EEG 031',\n",
       " 'EEG 032',\n",
       " 'EEG 033',\n",
       " 'EEG 034',\n",
       " 'EEG 035',\n",
       " 'EEG 036',\n",
       " 'EEG 037',\n",
       " 'EEG 038',\n",
       " 'EEG 039',\n",
       " 'EEG 040',\n",
       " 'EEG 041',\n",
       " 'EEG 042',\n",
       " 'EEG 043',\n",
       " 'EEG 044',\n",
       " 'EEG 045',\n",
       " 'EEG 046',\n",
       " 'EEG 047',\n",
       " 'EEG 048',\n",
       " 'EEG 049',\n",
       " 'EEG 050',\n",
       " 'EEG 051',\n",
       " 'EEG 052',\n",
       " 'EEG 054',\n",
       " 'EEG 055',\n",
       " 'EEG 056',\n",
       " 'EEG 057',\n",
       " 'EEG 058',\n",
       " 'EEG 059',\n",
       " 'EEG 060',\n",
       " 'EOG 061']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_raw.ch_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 events found on stim channel STI 014\n",
      "Event IDs: [ 1  2  3  4  5 32]\n"
     ]
    }
   ],
   "source": [
    "# extract event codes from the data if you have a specific channel for the trigger\n",
    "events = mne.find_events(cleaned_raw, stim_channel='STI 014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use annotations if you used a TTL pulse\n",
    "#events, events_dict = mne.events_from_annotations(clean_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's create a dictionary (also known as hash mapping), so that we know what happened in each epoch\n",
    "event_mapping = {'LA':1, 'RA':2, 'LV':3, 'RV':4, 'smiley':5, 'button_press':32}\n",
    "\n",
    "# 1 = left auditory, 2 = right auditory, 3 = left visual, 4 = right visual"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "Check the events structure: \n",
    "\n",
    "What represents the first column:\n",
    "\n",
    "Second column:\n",
    "\n",
    "Third column: \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mne.viz.plot_events(events, sfreq=cleaned_raw.info['sfreq']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "How did the paradigm work?\n",
    "\n",
    "What was the participants task? \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create epochs based on events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "320 matching events found\n",
      "Setting baseline interval to [-1.0006410259015925, 1.0006410259015925] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 320 events and 1203 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "epochs = mne.Epochs(cleaned_raw, events, event_mapping, tmin=-1, tmax=1, baseline=(None, None), preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "Extract the first epoch for left auditory stimuli\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_audit_epochs = epochs['LA'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "Get all epochs that contained an auditory stimulus\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "both_audit_epochs = epochs['LA', 'RA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot our first Event related potential (ERP)\n",
    "average over epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channels marked as bad:\n",
      "none\n"
     ]
    }
   ],
   "source": [
    "evoked_auditory = both_audit_epochs.average().plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n",
      "320 matching events found\n",
      "Setting baseline interval to [-1.0006410259015925, 1.0006410259015925] s\n",
      "Applying baseline correction (mode: mean)\n",
      "0 projection items activated\n",
      "Loading data for 320 events and 1203 original time points ...\n",
      "0 bad epochs dropped\n"
     ]
    }
   ],
   "source": [
    "# let's compare the evokeds before and after cleaning\n",
    "epochs_raw = mne.Epochs(raw, events, event_mapping, tmin=-1, tmax=1, baseline=(None, None), preload=True)\n",
    "# let's get both\n",
    "both_audit_epochs_raw = epochs_raw['LA', 'RA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "Plot both evoked plots next to each other in one figure. \n",
    "\n",
    "Add titles so we know which plot is before and which is after cleaning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[12, 3])\n",
    "\n",
    "both_audit_epochs_raw.average().plot(axes=ax[0], show=False);\n",
    "plt.title('before ica')\n",
    "both_audit_epochs.average().plot(axes=ax[1]);\n",
    "plt.title('after ica')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Discussion:</b>\n",
    "\n",
    "How and where do the plots differ?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Bonus:</b> \n",
    "\n",
    "Let's get rid of the remaining noisy segments using autoreject.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>LA: 72<br/>LV: 73<br/>RA: 73<br/>RV: 71<br/>button_press: 16<br/>smiley: 15</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-1.001 – 1.001 s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-1.001 – 1.001 s</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Epochs |  320 events (all good), -1.00064 – 1.00064 s, baseline -1.00064 – 1.00064 s, ~205.6 MB, data loaded,\n",
       " 'LA': 72\n",
       " 'RA': 73\n",
       " 'LV': 73\n",
       " 'RV': 71\n",
       " 'smiley': 15\n",
       " 'button_press': 16>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not part of MNE, so has to be imported\n",
    "from autoreject import AutoReject\n",
    "\n",
    "ar = AutoReject(n_interpolate=[1, 2, 4],\n",
    "                random_state=42,\n",
    "                picks=mne.pick_types(epochs.info, \n",
    "                                     eeg=True,\n",
    "                                     eog=False\n",
    "                                    ),\n",
    "                n_jobs=-1, \n",
    "                verbose=False\n",
    "                )\n",
    "\n",
    "epochs_clean, reject_log_clean = ar.fit_transform(epochs, return_log=True)\n",
    "\n",
    "epochs_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Caution: depending on the number of epochs, channels and the lenght of the epochs this might take a wile \n",
    "\n",
    "### => Patience, plus short coffee break "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what did we remove?\n",
    "\n",
    "fig, ax = plt.subplots(figsize=[10, 4])\n",
    "reject_log_clean.plot('horizontal', aspect='auto', ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "Plot both evoked plots next to each other in one figure. \n",
    "\n",
    "Add titles so we know which plot is before and which is after autoreject cleaning.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'after autoreject cleaning')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=[12, 3])\n",
    "\n",
    "epochs['LA', 'RA'].average().plot(axes=ax[0], show=False); # remember the semicolon prevents a duplicated plot\n",
    "plt.title('before autoreject cleaning')\n",
    "epochs_clean['LA', 'RA'].average().plot(axes=ax[1]);\n",
    "plt.title('after autoreject cleaning')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topomaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify times to plot at, as [min],[max],[stepsize]\n",
    "times = np.arange(0, 0.5, 0.1)\n",
    "\n",
    "epochs_clean['LA'].average().plot_topomap(times=times, average=0.050);\n",
    "epochs_clean['LV'].average().plot_topomap(times=times, average=0.050);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Discussion:</b>\n",
    "\n",
    "Do the topoplots differ? \n",
    "\n",
    "Do you expect them to differ?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Don't forget to save the cleaned epochs\n",
    "epochs_clean.save(Path(data_dir, 'clean-after_autoreject-epo.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-referencing \n",
    "### or in other words: what are we actually measuring?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Discussion:</b>\n",
    "\n",
    "electrical potentials are always a relative measure, but relative to what?\n",
    "\n",
    "how about choosing a reference on the floor?\n",
    "\n",
    "when do I have to choose the reference electrode?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create evoked object for left auditory epochs\n",
    "evoked_al = epochs_clean['LA'].average()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No projector specified for this dataset. Please consider the method self.add_proj.\n"
     ]
    }
   ],
   "source": [
    "# always check the signal\n",
    "evoked_al.plot();\n",
    "evoked_al.plot_joint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using GFP (eeg channels)\n",
      "combining channels using GFP (eeg channels)\n"
     ]
    }
   ],
   "source": [
    "# Usually we want to compare conditions\n",
    "evoked_lv = epochs_clean['LV'].average()\n",
    "mne.viz.plot_compare_evokeds([evoked_al, evoked_lv]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_montage = mne.channels.make_standard_montage(\"easycap-M1\")\n",
    "std_montage.plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_lv.plot_topo();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "evoked_lv.plot_topomap();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Discussion:</b>\n",
    "\n",
    "Which reference did they use? \n",
    "\n",
    "What to do if we don't know?\n",
    "\n",
    "</div> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Average reference: the average potential across all electrodes is subtracted from each individual electrode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    }
   ],
   "source": [
    "average_ref_epochs = epochs_clean.copy().set_eeg_reference(ref_channels='average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the average re-referenced epochs\n",
    "average_ref_epochs.save(Path(data_dir, 'average_ref-epo.fif'), overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check out [this page](https://neuraldatascience.io/7-eeg/erp_avg_reref.html) on re-referencing and the effects of different reference electrodes on the ERPs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_clean.average().plot_topomap(times=times, average=0.050);\n",
    "average_ref_epochs.average().plot_topomap(times=times, average=0.050);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Exercise:</b>  \n",
    "\n",
    "\n",
    "plot the re-referenced cleaned evoked contrast for left auditory vs left visual\n",
    "\n",
    "plot the difference between the conditions\n",
    "\n",
    "plot a shorter time window and a specific channel (you can choose which one)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combining channels using GFP (eeg channels)\n",
      "combining channels using GFP (eeg channels)\n"
     ]
    }
   ],
   "source": [
    "evokeds_diff = mne.combine_evoked([average_ref_epochs['LA'].average(), \n",
    "                                   average_ref_epochs['LV'].average()\n",
    "                                   ], \n",
    "                                  weights=[1, -1]\n",
    ")\n",
    "\n",
    "mne.viz.plot_compare_evokeds({'left auditory': average_ref_epochs['LA'].average(), 'left visual': average_ref_epochs['LV'].average()});\n",
    "\n",
    "evokeds_diff.plot();\n",
    "\n",
    "average_ref_epochs.plot_sensors();\n",
    "\n",
    "mne.viz.plot_compare_evokeds({'left auditory': average_ref_epochs['LA'].average().copy().crop(-0.2,0.5), 'left visual': average_ref_epochs['LV'].average().copy().crop(-0.2,0.5)}, picks=['EEG 048']);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take aways for re-referencing:\n",
    "\n",
    "- a priori hypothesis of what ERP components and where the biggest difference potential should be\n",
    "\n",
    "- re-referencing can't create a difference in the data that didn't exist before, it can only mask or unmask differences\n",
    "\n",
    "- average reference is a safe option (can be done post data collection), but careful if you look at very broad ERPs (e.g. P300), average reference may attenuate the experimental effect\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "expecon_3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
